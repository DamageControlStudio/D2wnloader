# UTOPIA-Downloader

**Python** **多线程下载** **分块下载** **断点续传**

由于手机尤其是 iPhone 根本没有下载工具，官方不允许这种东西上架。

因此考虑用 Python 写了这个下载器，当然，想在 iPhone 上跑脚本你需要先安装 Pythonista 或者类似的东西。

## D1wnloader

也就是原来目录中的 main.py  
主要解决断点续传、多线程分块下载问题。

2019-11-17 更新：

- 拼装前检查分块大小，如某分块未完成就结束则重试  
- 修正不重要的文案  

可能出现的 bug ：

- 如果网站并不返回 Content-Length 会引起错误，对于这种网站分块下载和断点续传也没什么意义；
- ~~如果第一次下载到一半不成功，第二次不能改 blocks_num 参数，否则就分块错乱了；~~ 已修正；
- 在 iPhone 7 上，目前发现下载超过1.7G的文件时，最后一步计算 sha256 会出现 Memory Error，但是那时已经“缝合”完毕，文件是完整的。当然也可以通过注释掉这个功能避免看见错误，不过这应该是 Pythonista 的问题；

## D2wnloader

### 目标

D2wnloader 计划成为 UTOPIA Downloader 的继任者，预计会具备以下特性：  

1. [ ] 能够自动、合理地增减分块数，达到最大下载速度
2. [x] 用法与 UTOPIA Downloader 尽可能不冲突
3. [ ] 如果效果好的话发布到 PyPI
4. [x] 下载结束的线程会继续“帮忙”下载未完成的部分
5. [x] 现在随意修改 block_num 也能从缓存文件继续下载了

### 设计

AAEK 据说是某五笔输入法【未开垦】的编码，无从考证。格式为 `AAEK = [(0,4), (5,11), (12,99) ...]`，用此形式表示未下载的部分，每对 tuple 表示 (开始,结束)，两头包含。所以：

- 如果 100 个字节的文件尚未下载时为：`[(0,99)]`，当下载了 50 至 58 字节后变成 `[(0,49),(59,99)]`。
- 根据 AAEK 可以推算出已下载了那些字节。
- 缓存文件命名：特征值_起始字节，比如 MD5XXX_0, MD5XXX_59。也同样需要合并机制，合并过程需要包含核对文件大小，也需要核对是否与 AAEK 矛盾。
- 分块小于一个阈值就可以不再分割了。

增加 worker 的策略：

- 找到 size 最大的一个分块，将其对应的 DLWorker 停下来。
- 当 DLWorker 执行回调函数的时候，会检查自己 curser 与 end 的关系，来判断是任务完成了，还是被提前停掉。
    1. 如果是前者，就再启动一个 Worker 去帮助其他较大的分块；
    2. 如果是后者，就将没完成的任务一分为二给两个新的 DLWorker。
- 当然，如果一个分块都还不足 2M（暂定）大小，就先不变动了。

工作流程：

1. 获取要下载文件的大小；
2. 启动测速线程；
3. __ask_for_work 申请与 block_num 数量相当的下载分块
    a. 充足就返回
    b. 不够就尝试分割
    c. 没有分块，先返回 []，然后尝试调用一个 worker 的 help
4. 跑起来的 worker 有 3 种结局
    a. 下载完毕，要求 __ask_for_work。如果还有任务，转生另 1 个 worker 继续下载
    b. 请求帮助。自己提前结束，未完成的部分交出，申请另 2 个 worker 继续下载。相当于线程 +1
    c. 退休。仅交出未完成的部分，不在继续。用于希望减少线程数

### TODO

- 监测速度明显下降时自动重新开始 D2wnloader
- 内存有限的情况下计算 md5 sha256
- 写一个 Pythonista 的 UI

### 问题与解决方案

- 在 Pythonista 上全是后台进程，没有停止按钮，因为主进程已经结束了。解决办法是用 Pythonista 搞一个 UI
- 测试发现，许多时候增加进程并不会增加下载速度，似乎是达到了某种限制，也可能这个想法根本就是玄学
- 合并缓存文件：不太需要这个功能，空浪费时间，增加出错的可能性
